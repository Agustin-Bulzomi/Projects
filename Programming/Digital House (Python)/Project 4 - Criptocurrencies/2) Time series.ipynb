{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7869fd-5d48-40cb-bed7-5b68908e51c3",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d08089-bf9e-4987-b90c-6f6ac1f940b1",
   "metadata": {},
   "source": [
    "En esta notebook se analizará la serie de tiempo de BTC. El desarrollo consta de tres partes: la primera prepara el dataset, la segunda aplica modelos de predicción y la tercera analiza estacionariedad tanto para la serie de tiempo como para los residuos de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d351e",
   "metadata": {},
   "source": [
    "# 1) Preparación previa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c04385",
   "metadata": {},
   "source": [
    "## Carga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec970724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.graphics.tsaplots import plot_predict\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "from scipy import stats\n",
    "from statistics import mode\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Se debe instalar pmdarima \n",
    "from pmdarima import auto_arima #!pip install pmdarima\n",
    "\n",
    "# Se debe instalar prophet\n",
    "from prophet import Prophet #!pip install prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "import itertools\n",
    "from prophet.diagnostics import performance_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb2f53",
   "metadata": {},
   "source": [
    "## Lectura y armado del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c9290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Agustin-Bulzomi/Projects/main/Programming/Digital%20House%20(Python)/Support%20Files/Final%20Project/coin_Bitcoin.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e71e1",
   "metadata": {},
   "source": [
    "Se realizan las modificaciones del dataset pertinentes para el análisis de series de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6923804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.index = pd.PeriodIndex(df.Date, freq = 'D')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef117f",
   "metadata": {},
   "source": [
    "Se agrega la columna Time index, necesaria para algunos modelos futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timeIndex'] = pd.Series(np.arange(len(df['Close'])), index = df.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e1862-8396-44ed-825f-027047fe2bb3",
   "metadata": {},
   "source": [
    "#### Se crean dummies de los meses, que serán utilizadas luego en un modelo que analiza estacionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69b631-a561-4c20-b4b9-6986b40d28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year\n",
    "dummies_mes = pd.get_dummies(df['Month'], drop_first = True, prefix = 'Month')\n",
    "df = df.join(dummies_mes)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6754d-ac28-4cdf-a058-aeccf31feb64",
   "metadata": {},
   "source": [
    "## División de Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71594d7-7e06-4593-a9d1-40c7a5c3977c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se procede con el tradicional 90-10, recomendado para time series y/o datasets muy grandes\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, shuffle=False)\n",
    "\n",
    "print(\"train shape\", df_train.shape)\n",
    "print(\"test shape\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd3cf9-6222-45a8-9f74-44128604a475",
   "metadata": {},
   "source": [
    "#### Ploteo de los dos datasets obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee725fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "f, ax = plt.subplots(figsize = (14,5))\n",
    "df_train.plot(kind = 'line', x = 'Date', y = 'Close', color = 'blue', label = \"Train\", ax = ax)\n",
    "df_test.plot(kind = 'line', x = 'Date', y = 'Close', color = 'red', label = \"Test\", ax = ax)\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.title(\"Rango para Train y para Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bad41d-e3dc-4467-b929-33d757c486c2",
   "metadata": {},
   "source": [
    "Visualmente ya se puede ver que es prácticamente imposible que un modelo de predicción estime el ascenso que tuvo el BTC en el último medio año, por lo que el split 90-10 tradicional no va a permitir evaluar modelos acertadamente. Se procede a hacer un split manual para analizar solo el último mes disponible de 2021 (febrero) como test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e16928-59d2-4caf-ab60-0e02ff3f903c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size_date = df[df['Date'] <= (df['Date'].max() - pd.DateOffset(days=31))].shape[0]\n",
    "df_train, df_test = train_test_split(df, train_size=train_size_date, shuffle=False)\n",
    "\n",
    "print(\"train shape\", df_train.shape)\n",
    "print(\"test shape\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff69a7b-7bb3-43e5-9210-6b27fd5b0a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3c559-ac0b-4747-b93d-d7fb1f76b814",
   "metadata": {},
   "source": [
    "#### Ploteo de los dos datasets obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca8146-9c5f-443e-9bdb-70319db1d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "f, ax = plt.subplots(figsize = (14,5))\n",
    "df_train.plot(kind = 'line', x = 'Date', y = 'Close', color = 'blue', label = \"Train\", ax = ax)\n",
    "df_test.plot(kind = 'line', x = 'Date', y = 'Close', color = 'red', label = \"Test\", ax = ax)\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.title(\"Rango para Train y para Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae55bf-d949-4ddf-923f-4614fe43bf83",
   "metadata": {},
   "source": [
    "## Generación de la serie en escala logarítmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_value'] = np.log(df_train['Close'])\n",
    "df_test['log_value'] = np.log(df_test['Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364992d",
   "metadata": {},
   "source": [
    "#### Ploteo del Target y Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9a5d6-14a2-46c0-83cd-7af713f5b405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.plotting.register_matplotlib_converters()\n",
    "f, ax = plt.subplots(figsize = (14,5))\n",
    "df_train.plot(kind = 'line', x = 'Date', y = 'log_value', color = 'blue', label = \"Train\", ax = ax)\n",
    "df_test.plot(kind = 'line', x = 'Date', y = 'log_value', color = 'red', label = \"Test\", ax = ax)\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.title(\"Rango para Train y para Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79ca6a",
   "metadata": {},
   "source": [
    "# 2) Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cde297",
   "metadata": {},
   "source": [
    "Se utilizará una plétora de herramientas y recursos para analizar las series de tiempo y sus implicancias. En cada paso se irá visualizando los resultados y almacenando su información para, al final de la notebook, compararlos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7230e893-ee76-4dd8-9895-6866185c8d83",
   "metadata": {},
   "source": [
    "#### Se define una función para calcular el RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1338634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(actual, predicted):\n",
    "  mse = (predicted - actual) ** 2\n",
    "  rmse = np.sqrt(mse.sum() / mse.count())\n",
    "  return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930912b1-6a16-41ae-8da8-cf5799f1d6e9",
   "metadata": {},
   "source": [
    "#### Se define una función para calcular el MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(actual, predicted): \n",
    "  actual, predicted = np.array(actual), np.array(predicted)\n",
    "  return np.mean(np.abs((actual - predicted) / actual)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b7a75-f942-4282-93ef-5a0b46d8dd51",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Se define una función para crear los gráficos de cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be112d94-7e30-40ef-804c-d03f93317b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_time_series(df_train, df_test, model_name, series = 'Close'):\n",
    "  fig, axes = plt.subplots(1,2, figsize = (16, 6))\n",
    "\n",
    "  df_train.plot(kind = \"line\", y = [series, model_name], ax = axes[0])\n",
    "  axes[0].set_title(\"Train Data\", size = 16)\n",
    "  axes[0].set_xlabel(\"Year\", size = 14)\n",
    "\n",
    "  df_test.plot(kind = \"line\", y = [series, model_name], ax = axes[1])\n",
    "  axes[1].set_title(\"Test Data\", size = 16)\n",
    "  axes[1].set_xlabel(\"Date\", size = 14)\n",
    "  # Por el salto de mes que se da de enero a febrero, el código plotea los x ticks con variedad de formatos. Se lo modifica:\n",
    "  date_format = mdates.DateFormatter('%b-%d')\n",
    "  axes[1].xaxis.set_major_formatter(date_format)\n",
    "  weekday_locator = mdates.WeekdayLocator(byweekday = mdates.MO)\n",
    "  axes[1].xaxis.set_major_locator(weekday_locator)\n",
    "\n",
    "  # Se agregan el RMSE y el MAPE debajo de los plots\n",
    "  rmse = RMSE(df_test[series], df_test[model_name])\n",
    "  mape = MAPE(df_test[series], df_test[model_name])\n",
    "  rmse_mape_text = f\"RMSE = {rmse:.2f} | MAPE = {mape:.2f}%\"\n",
    "  plt.text(0.5, 0.0, rmse_mape_text, ha = 'center', transform = fig.transFigure, fontsize = 14)\n",
    "  \n",
    "  #Se agrega el título del plot\n",
    "  formatted_model_name = model_name.replace(\"_\", \" \").title()\n",
    "  plt.suptitle(f\"Predicción del precio de BTC con {formatted_model_name}\", size = 18, y = 1.02)\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dbe2e",
   "metadata": {},
   "source": [
    "## a) Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d31e52",
   "metadata": {},
   "source": [
    "#### Se aplica el modelo de media constante a train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd833910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se calcula el promedio:\n",
    "model_mean_pred = df_train['Close'].mean()\n",
    "\n",
    "# La predicción es fija y es la misma para el set de testeo y de entrenamiento:\n",
    "df_train['mean'] = model_mean_pred\n",
    "df_test['mean'] = model_mean_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bc073",
   "metadata": {},
   "source": [
    "#### Ploteo de las predicciones vs la serie real y cálculo de RMSE y MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c511a-fac5-4c7b-953c-6d0895b8e488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841b241",
   "metadata": {},
   "source": [
    "#### Se guardan los resultados en un DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb21bd",
   "metadata": {},
   "source": [
    "El mismo será reutilizado para almacenar los resultados de los distintos modelos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns = [\"Model\", \"RMSE\",\"MAPE\"])\n",
    "df_results.loc[0, \"Model\"] = \"Mean\"\n",
    "df_results.loc[0, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['mean']),1)\n",
    "df_results.loc[0, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['mean']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbf41a",
   "metadata": {},
   "source": [
    "## b) Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfdc28",
   "metadata": {},
   "source": [
    "Se crea el shift de target en train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e26e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['close_shift'] = df_train['Close'].shift()\n",
    "# La primera observación va a quedar en nan, por lo que se reemplaza por el valor siguente:\n",
    "df_train['close_shift'].fillna(method = 'bfill', inplace = True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9770ea",
   "metadata": {},
   "source": [
    "Se crea el shift de target en test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['close_shift'] = df_test['Close'].shift()\n",
    "# Se puede reemplazar el primer nan con el último valor del set de entrenamiento:\n",
    "df_test.iloc[0,26] = df_train.iloc[-1,0]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1292ad79",
   "metadata": {},
   "source": [
    "Lag de un período:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411916f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind = 'scatter', y = 'Close', x = 'close_shift', s = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65f680",
   "metadata": {},
   "source": [
    "Diferencias entre Target y el lag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab8d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['close_diff'] = df_train['Close'] - df_train['close_shift']\n",
    "df_train['close_diff'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868268d2-5226-4131-bda6-1c0026377091",
   "metadata": {},
   "source": [
    "#### Ploteo de las predicciones vs la serie real y cálculo de RMSE y MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4bbca-525a-44d8-ba16-5197e6c073f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['random_walk'] = df_train['close_shift']\n",
    "df_test['random_walk'] = pd.Series(df_train['Close'][-1], index = df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63298ff-0181-4f6d-916b-10a9696187e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'random_walk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac6d25c-8d4a-4cef-85af-09bf9b853b72",
   "metadata": {},
   "source": [
    "#### Se almacenan los valores de RMSE y MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b89524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[1, \"Model\"] = \"Random Walk\"\n",
    "df_results.loc[1, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['random_walk']),1)\n",
    "df_results.loc[1, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['random_walk']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a5716",
   "metadata": {},
   "source": [
    "## c) Linear Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fd8de",
   "metadata": {},
   "source": [
    "#### Se crea una columna en train con el predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe358c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = smf.ols('Close ~\ttimeIndex', data = df_train).fit()\n",
    "\n",
    "df_train['linear_trend'] = model_linear.predict(df_train['timeIndex'])\n",
    "df_test['linear_trend'] = model_linear.predict(df_test['timeIndex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6796b",
   "metadata": {},
   "source": [
    "#### Ploteo de las predicciones vs las series reales, en train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ad3b9-5fe1-4aea-8cdc-991d7334676c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'linear_trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8bc33",
   "metadata": {},
   "source": [
    "#### Se almacenan los valores de RMSE y MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[2, \"Model\"] = \"Linear Trend\"\n",
    "df_results.loc[2, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['linear_trend']),1)\n",
    "df_results.loc[2, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['linear_trend']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ca89d",
   "metadata": {},
   "source": [
    "## d) Back Log Transformation + Linear Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4eda52-72a3-442a-ba64-da0024a2f307",
   "metadata": {},
   "source": [
    "Se fitea el modelo Linear Trend con escala logarítmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b579a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = smf.ols('log_value ~ timeIndex', data = df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688518cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['log_linear'] = model_log.predict(df_train[['timeIndex']])\n",
    "df_test['log_linear'] = model_log.predict(df_test[['timeIndex']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad83316-53c0-497e-8e49-3d9e4e06873d",
   "metadata": {},
   "source": [
    "Se invierte la escala logarítmica del modelo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_linear'] = np.exp(df_train['log_linear'])\n",
    "df_test['back_linear'] = np.exp(df_test['log_linear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcd7c0",
   "metadata": {},
   "source": [
    "#### Ploteo de las predicciones vs las series reales, en train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b78bf-7913-470a-b19d-95fe135c9a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'back_linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21ae6b-3227-4aaa-89fe-d28e4aeaf1f4",
   "metadata": {},
   "source": [
    "#### Se almacenan los valores de RMSE y MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd772de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[3, \"Model\"] = \"Back Log Linear\"\n",
    "df_results.loc[3, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['back_linear']),1)\n",
    "df_results.loc[3, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['back_linear']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b5bdf",
   "metadata": {},
   "source": [
    "## e) Back Log Transformation + Linear Trend + Estacionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7126e4-65a9-4499-b6c4-38cad28a8080",
   "metadata": {},
   "source": [
    "En la tercera sección de esta notebook se utilizarán algunas herramientas para analizar la estacionalidad de la serie. Sin embargo, igualmente se analiza un caso de modelo con agregado de estacionalidad para ver si aporta al resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f691b00-e43d-4a21-870b-960c5d6a3cdf",
   "metadata": {},
   "source": [
    "#### Creación del modelo con dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f95dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_linear_est = smf.ols('log_value ~ timeIndex + Month_2 + Month_3 + Month_4 + Month_5 + Month_6 + Month_7 + Month_8 + Month_9 + Month_11 + Month_12', data = df_train).fit()\n",
    "\n",
    "df_train['log_linear_est'] = log_linear_est.predict(df_train[['timeIndex', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6','Month_7', 'Month_8', 'Month_9','Month_10','Month_11','Month_12']])\n",
    "\n",
    "df_test['log_linear_est'] = log_linear_est.predict(df_test[['timeIndex', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6','Month_7', 'Month_8', 'Month_9','Month_10','Month_11','Month_12']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562271f1-699f-43e4-b2a1-c61a77143e50",
   "metadata": {},
   "source": [
    "Se invierte la escala logarítmica del modelo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd059950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['back_linear_est'] = np.exp(df_train['log_linear_est'])\n",
    "df_test['back_linear_est'] = np.exp(df_test['log_linear_est'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4c643",
   "metadata": {},
   "source": [
    "#### Ploteo de las predicciones vs las series reales, en train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fb643-3950-493b-8ef9-1699aa8989c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'back_linear_est')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ca3dc-bd94-4f6d-926e-99a64327c867",
   "metadata": {},
   "source": [
    "#### Se comparan los valores de RMSE y MAPE del Back Transformation sin y con el agregado de los meses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd3fed-c2c7-4f30-8dd4-a4f46676acea",
   "metadata": {},
   "source": [
    "A pesar de que Back Transformation con y sin Estimate parecen idénticos, hay unas mínimas diferencias en los decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b729b4c-b736-4a9d-b11a-a08809b47fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El RMSE de Back Transformation es \", RMSE(df_test['Close'], df_test['back_linear']), \", mientras que el de Back Transformation + Estacionalidad es \", RMSE(df_test['Close'], df_test['back_linear_est']), \".\\n La diferencia es de\", (RMSE(df_test['Close'], df_test['back_linear']) - RMSE(df_test['Close'], df_test['back_linear_est'])))\n",
    "print(\"\\nEl MAPE de Back Transformation es \", MAPE(df_test['Close'], df_test['back_linear']), \", mientras que el de Back Transformation + Estacionalidad es \", MAPE(df_test['Close'], df_test['back_linear_est']), \".\\n La diferencia es de\", (MAPE(df_test['Close'], df_test['back_linear']) - MAPE(df_test['Close'], df_test['back_linear_est'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251429bb-1a06-4677-9d13-360a9adde44f",
   "metadata": {},
   "source": [
    "Por ser ínfima la diferencia, no se almacena el valor del modelo con Estimate incluido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab1c74",
   "metadata": {},
   "source": [
    "## f) Simple Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c884a1d-259e-4598-a073-a79f7df75b56",
   "metadata": {},
   "source": [
    "Se aplica Cross Validation para averiguar el nivel óptimo de Simple Smoothing del train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1580e5-3bf7-43e5-92df-92eba9f865c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estandarizan los datos\n",
    "scaler = StandardScaler()\n",
    "values_standardized = scaler.fit_transform(df_train['Close'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Se define el rango de hiperparametros a teastear\n",
    "hyperparam_range = np.linspace(0.001, 1, num=100)\n",
    "\n",
    "# Se calcula el error de cada hiperparámetro utilizando CV\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "mse_errors = []\n",
    "for alpha in hyperparam_range:\n",
    "    errors = []\n",
    "    for train, test in tscv.split(values_standardized):\n",
    "        model = SimpleExpSmoothing(values_standardized[train]).fit(smoothing_level=alpha, optimized=False)\n",
    "        predictions_standardized = model.forecast(len(test))\n",
    "        actual_standardized = values_standardized[test]\n",
    "        predictions = scaler.inverse_transform(predictions_standardized.reshape(-1, 1)).flatten()\n",
    "        actual = scaler.inverse_transform(actual_standardized.reshape(-1, 1)).flatten()\n",
    "        error = mean_squared_error(predictions, actual)\n",
    "        errors.append(error)\n",
    "    mse_errors.append(np.mean(np.array(errors)))\n",
    "\n",
    "# Se encuentra el hiperparámetro óptimo\n",
    "optimal_alpha = hyperparam_range[np.argmin(mse_errors)]\n",
    "print('Optimal alpha:', optimal_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d07ae-9b14-4bc9-9ddd-5411207b87f4",
   "metadata": {},
   "source": [
    "#### Se fitean varios modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b430ef-b813-43c5-a5dc-23145a785102",
   "metadata": {},
   "source": [
    "Se realizará el proceso 3 veces para comparar los resultados en test. El primer caso será uno sin suavizado: en ese caso, Simple Smoothing equivale a un modelo Standard Naive (por lo que se espera que el resultado sea el mismo que el que se obtuvo aplicando Random Walk). Los otros dos serán con distintos grados de suavizado, siendo uno el obtenido mediante Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_smoothing = SimpleExpSmoothing(df_train['Close']).fit(smoothing_level = 1, optimized = False)\n",
    "df_train['standard_naive'] = model_no_smoothing.fittedvalues\n",
    "df_test['standard_naive'] = model_no_smoothing.forecast(len(df_test))\n",
    "\n",
    "model_simple_smoothing = SimpleExpSmoothing(df_train['Close']).fit(smoothing_level = 0.1, optimized = False)\n",
    "df_train['simple_smoothing'] = model_simple_smoothing.fittedvalues\n",
    "df_test['simple_smoothing'] = model_simple_smoothing.forecast(len(df_test))\n",
    "\n",
    "model_strong_simple_smoothing = SimpleExpSmoothing(df_train['Close']).fit(smoothing_level = optimal_alpha, optimized = False)\n",
    "df_train['strong_simple_smoothing'] = model_strong_simple_smoothing.fittedvalues\n",
    "df_test['strong_simple_smoothing'] = model_strong_simple_smoothing.forecast(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879626c",
   "metadata": {},
   "source": [
    "#### Ploteo de las predicciones vs las series reales, en train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11847e-461b-4439-809f-362a6166e3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'standard_naive')\n",
    "plot_time_series(df_train, df_test, 'simple_smoothing')\n",
    "plot_time_series(df_train, df_test, 'strong_simple_smoothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe388b-84d4-40de-8df7-b68d23159535",
   "metadata": {},
   "source": [
    "Como se puede observar, el resultado obtenido utilizando el alpha que arroja el cross validation sobre train presenta underfitting, ya que da un rendimiento inferior en comparación con un alpha superior. En otras palabras, el mayor suavizado es menos eficiente que no suavizar (Standard Naive), y mucho menos que un suavizado leve. Esto es razonable en casos como el del presente dataset: los patrones históricos de 2014 a 2017 tienen poca relevancia para predecir movimientos actuales en el precio, en comparación a tendencias recientes como lo son las del 2020 con el boom de las criptomonedas. Un alpha más alto, con menor suavizado y mayor overfitting, podría capturar mejor las fluctuaciones a corto plazo que son más significativas en mercados criptográficos en constante evolución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7b403-d288-4f3f-a5d2-7d0c65779e52",
   "metadata": {},
   "source": [
    "#### Se almacenan los valores de RMSE y MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c350f3-1253-4cdf-a81b-5e56e90bec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[4, \"Model\"] = \"Simple Smoothing\"\n",
    "df_results.loc[4, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['simple_smoothing']),1)\n",
    "df_results.loc[4, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['simple_smoothing']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468ac01",
   "metadata": {},
   "source": [
    "## g) ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5afbd-48f5-47d0-90f4-8e6e76a3512c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stepwise_fit = auto_arima(df_train['Close'], trace = True, suppress_warnings = True)\n",
    "model_ARIMA = ARIMA(df_train['Close'], order = stepwise_fit.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9fae6e-be26-4d48-b1bf-dc6ed0aa89b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['arima'] = model_ARIMA.fit().fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402b024-26f4-4bcc-8396-57a50db1a36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_ARIMA = model_ARIMA.fit().get_forecast(steps=len(df_test))\n",
    "df_test['arima'] = forecast_ARIMA.predicted_mean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337922c7-1179-4128-979b-8f405bda4ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, 'arima')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570ffe0",
   "metadata": {},
   "source": [
    "#### Se observa el summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_ARIMA.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ea1f2-6d9a-47aa-84de-0ea9ce9094c8",
   "metadata": {},
   "source": [
    "#### Se almacenan los valores de RMSE y MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66b2e7-afee-4aa4-af03-c2d02a3e3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[5, \"Model\"] = \"ARIMA\"\n",
    "df_results.loc[5, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['arima']),1)\n",
    "df_results.loc[5, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['arima']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9c9b3-a2dd-400b-86cf-082b1ac5eca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## h) Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd42a1-60bd-4d23-a2b2-d347105b190e",
   "metadata": {},
   "source": [
    "#### Se busca la mejor combinación de hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0ca73-7a9c-4b73-81eb-b81f7b8bb19d",
   "metadata": {},
   "source": [
    "Prophet requiere que la columna Date se llame \"ds\" y la columna de los precios \"y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed683fe6-b89f-44d6-98d1-0d6eb3fb08c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['ds'] = df_train['Date']\n",
    "df_test['ds'] = df_test['Date']\n",
    "df_train['y'] = df_train['Close']\n",
    "df_test['y'] = df_test['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9c2ba-2722-4260-a416-b2478c6c6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código toma mucho tiempo. Dependiendo del poder de procesamiento de la computadora, puede demorar alrededor de una hora.\n",
    "\n",
    "# Como el proceso produce más de 100 líneas de output por cada iteración de prueba de hiperparámetros, se lo reduce via logging:\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "# De esta manera, solo se produce la barra de progreso de cada iteración.\n",
    "\n",
    "# Se crea una grilla con distintos valores de parámetros posibles a testear\n",
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.005, 0.01, 0.1, 0.5, 1],\n",
    "    'seasonality_prior_scale': [1, 10, 20, 30, 40],\n",
    "    'seasonality_mode' : ('additive', 'multiplicative'),\n",
    "    'daily_seasonality' : [False, True]}\n",
    "\n",
    "# Genera todas las combinaciones de parámetros\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []\n",
    "\n",
    "# Usa cross validation para evaluar los parámetros\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(df_train)  # Fitea el modelo con los parámetros obtenidos\n",
    "    df_cv = cross_validation(m, initial='2500 days', period= '15 days', horizon='31 days')\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4767f09-cc64-4313-a091-5016c272e5da",
   "metadata": {},
   "source": [
    "#### Análisis de cuál tuvo mejor rendimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979e2e1-ccd9-4536-9623-112244d569d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierten los resultados en un df\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "\n",
    "# Se encuentran los mejores hiperparámetros\n",
    "best_params = tuning_results.loc[tuning_results['rmse'].idxmin()]\n",
    "print(\"Best parameters:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628b34c-9969-4f41-8c3e-ab4c544a8dee",
   "metadata": {},
   "source": [
    "#### Aplicación de los hiperparámetros sobre el modelo y fiteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b049c5-8d7e-4ea7-9611-3f3979c0b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el modelo con los mejores parámetros obtenidos\n",
    "prophet_model = Prophet(changepoint_prior_scale = best_params['changepoint_prior_scale'],\n",
    "                        seasonality_prior_scale = best_params['seasonality_prior_scale'],\n",
    "                        seasonality_mode = best_params['seasonality_mode'],\n",
    "                        daily_seasonality = best_params['daily_seasonality'])\n",
    "\n",
    "# Se fitea el modelo\n",
    "prophet_model.fit(df_train)\n",
    "\n",
    "# Se crea un Dataframe para realizar las predicciones\n",
    "future = prophet_model.make_future_dataframe(periods=len(df_test), freq='D')\n",
    "\n",
    "# Se realizan las predicciones\n",
    "forecast = prophet_model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49bd350-2075-4edd-8c7d-5b047d4751af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se insertan los resultados en el dataset utilizando el mismo esquema que el de los anteriores modelos\n",
    "forecast_values = forecast['yhat'].values\n",
    "df_train['prophet'] = forecast_values[:len(df_train)]\n",
    "df_test['prophet'] = forecast_values[-len(df_test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f3e15-f2de-46c8-8b48-94312e190a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_time_series(df_train, df_test, \"prophet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96aaefd-e9b0-4de1-a254-10381764e964",
   "metadata": {},
   "source": [
    "#### Se almacenan los valores de RMSE y MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52ef7e-4196-45e2-b6bd-87c74044f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[6, \"Model\"] = \"Prophet\"\n",
    "df_results.loc[6, \"RMSE\"] = round(RMSE(df_test['Close'], df_test['prophet']),1)\n",
    "df_results.loc[6, \"MAPE\"] = round(MAPE(df_test['Close'], df_test['prophet']),1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d84d8e",
   "metadata": {},
   "source": [
    "# 3) Comparación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed846590",
   "metadata": {},
   "source": [
    "#### Análisis de RMSE y MAPE visualizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19a945-bc3e-4bed-b28c-bc0507d0f20a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize = (22, 13))\n",
    "ax1.set_xlabel('Modelos', fontsize = 22)\n",
    "ax1.set_ylabel('MAPE', fontsize = 20, color = 'b')\n",
    "ax1.bar(df_results.index - 0.2, df_results.MAPE, width = 0.4, color = 'b', linewidth = 2, label = \"MAPE\")\n",
    "ax1.tick_params(axis = 'y', labelcolor = 'b', labelsize = 17)\n",
    "ax1.tick_params(axis = 'x', labelsize = 15)\n",
    "ax1.set_ylim([0, 99])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('RMSE', fontsize = 20, color = 'r')\n",
    "ax2.bar(df_results.index + 0.2, df_results.RMSE, width = 0.4, color = 'r', linewidth = 2, label = \"RMSE\")\n",
    "ax2.tick_params(axis = 'y', labelcolor = 'r', labelsize = 17)\n",
    "ax2.set_ylim([0, 50000])\n",
    "\n",
    "plt.axvline(x = 'Mean', color = 'grey', linestyle = '--', lw = 1.3)\n",
    "plt.axvline(x = 'Random Walk',color = 'grey', linestyle = '--', lw = 1.3)\n",
    "plt.axvline(x = 'Linear Trend', color = 'grey', linestyle = '--', lw = 1.3)\n",
    "plt.axvline(x = 'Back Log Linear Trend' , color = 'grey', linestyle = '--', lw = 1.3)\n",
    "plt.axvline(x = 'Simple Smoothing', color = 'grey', linestyle = '--', lw = 1.3)\n",
    "plt.axvline(x = 'ARIMA', color = 'grey', linestyle = '--', lw = 1.3)\n",
    "plt.axvline(x = 'Prophet', color = 'grey', linestyle = '--', lw = 1.3)\n",
    "\n",
    "plt.grid(which = 'major', axis = 'y', color = 'black', lw = 0.4, alpha = 0.6)\n",
    "plt.suptitle(\"Comparación de resultados\", fontsize = 24, y = 0.94)\n",
    "legend1 = ax1.legend(loc = (0.86, 0.9), fontsize = 18)\n",
    "legend2 = ax2.legend(loc = (0.86, 0.82), fontsize = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dfef1-0450-4d99-ba21-0d161f7c45a7",
   "metadata": {},
   "source": [
    "# 3) Análisis de estacionalidad y autocorrelación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319ab51-aa41-4050-96c9-9224f4b87a25",
   "metadata": {},
   "source": [
    "A continuación, se analizarán ACF, PACF y Dickey Fuller sobre la serie de tiempo de BTC y sobre los residuos de algunos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c1274-de3b-4104-9e09-212336d7ec70",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Se crea una función para plotear una serie con información sobre ACF, PACF y su estacionalidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddd2ed-687c-4a8e-b7c0-ab2111491673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tsplot(y, model_name = None, lags = None, figsize = (12, 7), style = 'bmh'):\n",
    "    \"\"\"\n",
    "    Plotea la serie de tiempo, el ACF y PACF y el test de Dickey–Fuller\n",
    "    \n",
    "    y - serie de tiempo\n",
    "    model_name - nombre del modelo con default None para cuando se desee plotear la serie de tiempo de BTC, en vez de los residuos del modelo\n",
    "    lags - cuántos lags incluir para el cálculo de la ACF y PACF\n",
    "    \"\"\"\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "\n",
    "    with plt.style.context(style):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (2, 2)\n",
    "\n",
    "        # Se definen ejes\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "\n",
    "        y.plot(ax=ts_ax)\n",
    "\n",
    "        # Se obtiene el p-value con H0: raiz unitaria presente\n",
    "        result = sm.tsa.stattools.adfuller(y)\n",
    "        p_value = result[1]\n",
    "\n",
    "        if model_name is not None:\n",
    "            ts_ax.set_title(f\"Análisis de los residuos del modelo {model_name}\", fontsize=18)\n",
    "        else:\n",
    "            ts_ax.set_title(\"Análisis de la serie de tiempo de BTC\", fontsize=18)\n",
    "\n",
    "        # Se agrega el texto del Dickey Fuller\n",
    "        adf_text = f\"ADF Statistic: {round(result[0],2)}\\n\"\n",
    "        adf_text += f\"p-value: {round(result[1],4)}\"\n",
    "\n",
    "        # Se añade el texto del Dickey Fuller como anotación\n",
    "        annotation_box = dict(boxstyle='square,pad=0.5', facecolor='white', edgecolor='black', alpha=1)\n",
    "        annotation = ts_ax.annotate(adf_text, xy=(0.11, 0.75), xycoords='axes fraction', ha='center', fontsize=12, bbox=annotation_box)\n",
    "\n",
    "        # Se añade un cuadro para el texto de Dickey Fuller\n",
    "        annotation_bbox = annotation.get_bbox_patch()\n",
    "        annotation_bbox.set_boxstyle(\"round,pad=0.3\", pad=0.5)\n",
    "\n",
    "        # Plot de autocorrelacion\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "        # Plot de autocorrelacion parcial\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b7f92-7571-4910-bf3b-1eeb33b32231",
   "metadata": {},
   "source": [
    "## Serie de BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b0e0d-83fb-4c89-8623-9c41f88ef055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsplot(df_train['Close'], lags = 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea6ff9-4afb-4b40-b486-0f7f610b20dd",
   "metadata": {},
   "source": [
    "## Residuos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a852baf-f397-4afa-8ca9-21f30afe71f0",
   "metadata": {},
   "source": [
    "#### Se crea la variable de cada residuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec9620-4c85-4966-848c-0afdd8e9f48c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "residue_mean = df_train['Close'] - df_train['mean']\n",
    "residue_random_walk = df_train['Close'] - df_train['random_walk']\n",
    "residue_linear_trend = df_train['Close'] - df_train['linear_trend']\n",
    "residue_back_linear = df_train['Close'] - df_train['back_linear']\n",
    "residue_simple_smoothing = df_train['Close'] - df_train['simple_smoothing']\n",
    "residue_arima = df_train['Close'] - df_train['arima']\n",
    "residue_prophet = df_train['Close'] - df_train['prophet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bee34-559b-4cb4-8bcc-bde2c7e6610c",
   "metadata": {},
   "source": [
    "#### Se plotean todos los residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd56ee-cdbd-4e04-b9ef-a8f52197784d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "residues = [residue_mean, residue_random_walk, residue_linear_trend, residue_back_linear, residue_simple_smoothing, residue_arima, residue_prophet]\n",
    "\n",
    "for residue, name in zip(residues, [\"Mean\", \"Random Walk\", \"Linear Trend\", \"Back Linear\", \"Simple Smoothing\", \"ARIMA\", \"Prophet\"]):\n",
    "    tsplot(residue, model_name=name, lags=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e4300-13cb-420c-ad46-713f523f4d26",
   "metadata": {},
   "source": [
    "## Análisis\n",
    "\n",
    "#### Serie de tiempo de BTC\n",
    "\n",
    "La estadística ADF de 0.7, junto con un p value de 0.99, indican en conjunto que la prueba de Dickey-Fuller Aumentada no logra proporcionar una evidencia sólida en contra de la presencia de una raíz unitaria en la serie de tiempo del BTC. Esto sugiere que los datos siguen siendo no estacionarios, potencialmente mostrando tendencias y patrones que pueden afectar el análisis y la predicción.\n",
    "\n",
    "#### Residuos de modelos\n",
    "\n",
    "Algunos valores de p value y de estadística de ADF son resultados esperados:\n",
    "\n",
    "1) Los valores para los residuos de Mean son idénticos a los de la serie de BTC.\n",
    "2) Los valores para los residuos de Random Walk, Simple Smoothing con poco suavizado y ARIMA en la configuración elegida dan estacionariedad perfecta. Esto se debe a que los valores que los modelos proponen para train son sumamente similares a los actuales de train.\n",
    "\n",
    "Algunas conclusiones que se pueden realizar sobre otros modelos son:\n",
    "\n",
    "1) Linear Trend\n",
    "    - Estadística ADF: -1.36\n",
    "    - Valor p: 0.6\n",
    "    - Análisis: La estadística ADF de -1.36 sugiere no estacionariedad, ya que no es fuertemente negativa. El valor p alto de 0.6 indica que no hay suficiente evidencia para rechazar la hipótesis nula de una raíz unitaria, lo que respalda la idea de no estacionariedad.\n",
    "\n",
    "\n",
    "2) Back Log Linear Trend\n",
    "    - Estadística ADF: -2.84\n",
    "    - Valor p: 0.05\n",
    "    - Análisis: La estadística ADF de -2.84 es más negativa, lo que sugiere una evidencia más fuerte en contra de la presencia de una raíz unitaria e indica una mayor probabilidad de estacionariedad. El valor p de 0.05 es relativamente bajo, lo que indica que existe alguna evidencia para rechazar la hipótesis nula de una raíz unitaria, lo cual concuerda con la estadística ADF que sugiere potencial estacionariedad.\n",
    "\n",
    "\n",
    "3) Prophet\n",
    "    - Estadística ADF: -4.13\n",
    "    - Valor p: 0.0009\n",
    "    - Análisis: La estadística ADF muy baja de -4.13 sugiere una evidencia sólida en contra de la presencia de una raíz unitaria e indica una alta probabilidad de estacionariedad. El valor p muy bajo de 0.0009 confirma esta evidencia, rechazando fuertemente la hipótesis nula de una raíz unitaria y respaldando la conclusión de estacionariedad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
