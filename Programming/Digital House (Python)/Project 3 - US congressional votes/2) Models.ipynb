{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Preparación previa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votos_final = pd.read_csv('votos_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Análisis de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a crear dos heatmaps para observar la correlación de las variables. En el primer caso, entre las independientes (leyes) y el Target (partido). Considerando que el mismo en valor 1 es demócrata y en 0 es republicano, los colores representarán la cercanía ideológica a cada partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "heatmap = sns.heatmap(votos_final.corr(numeric_only = True)[['Target']].sort_values(by='Target',ascending=False),\n",
    "                      vmin=-1, vmax=1, annot=True, cmap='RdYlBu')\n",
    "heatmap.set_title('Correlación con Target', fontdict={'fontsize':14}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar se analiza la correlación entre todas las variables. Aquí los valores representan oposición ideológica: valores cercanos a -1 indican que raramente uno votaría igual en ambas leyes, mientras que valores cercanos a 1 indican una fuerte correlación ideológica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=1.5)\n",
    "heatmap_variables = sns.heatmap(round(votos_final.corr(numeric_only = True),2), annot=True, vmin=-1, vmax=1, cmap='RdYlGn');\n",
    "heatmap_variables.set_title('Correlación entre variables', fontdict={'fontsize':24}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Preparación para modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide el dataset entre training y test, utilizando la columna Target creada a partir de la columna Class Name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = votos_final.iloc[:,1:17]\n",
    "y = votos_final[\"Target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica que coincidan las proporciones del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Proporciones del Train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"Proporciones del Test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estandarizan los datos para que la regularización sea correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizará la métrica del valor mayoritario como base para el rendimiento de los modelos a probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_mayor = y_test.value_counts(normalize=True).max()*100\n",
    "print(\"El porcentaje de demócratas es de\", round(valor_mayor, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se ajusta el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = GaussianNB()\n",
    "nbc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_nb = nbc.predict(X_test.values)\n",
    "y_probs_nb = nbc.predict_proba(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy =', accuracy_score(y_test, y_preds_nb).round(2))\n",
    "print('Recall =', recall_score(y_test, y_preds_nb).round(2))\n",
    "print('Precision =', precision_score(y_test, y_preds_nb).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_preds_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_votos = confusion_matrix(y_test, y_preds_nb)\n",
    "plt.plot(30)\n",
    "ax = sns.heatmap(gnb_votos, annot=True, cmap='RdYlGn', cbar=False,\n",
    "                    annot_kws={\"size\": 14}, fmt='g')\n",
    "\n",
    "plt.title('Matriz de confusión', size =16)\n",
    "plt.xlabel('Valores previstos', size = 13)\n",
    "plt.ylabel('Valores verdaderos', size=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se ajusta el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticR = LogisticRegression()\n",
    "logisticR.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lg = logisticR.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy =', accuracy_score(y_test, y_pred_lg).round(2))\n",
    "print('Recall =', recall_score(y_test, y_pred_lg).round(2))\n",
    "print('Precision =', precision_score(y_test, y_pred_lg).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_votos = confusion_matrix(y_test, y_pred_lg)\n",
    "plt.plot(30)\n",
    "ax = sns.heatmap(cm_votos, annot=True, cmap='RdYlGn', cbar=False,\n",
    "                    annot_kws={\"size\": 14}, fmt='g')\n",
    "\n",
    "plt.title('Matriz de confusión', size =16)\n",
    "plt.xlabel('Valores previstos', size = 13)\n",
    "plt.ylabel('Valores verdaderos', size=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Optimización vía Umbral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia el umbral de decisión para bajar la tasa de falsos positivos y analizar la variación en los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs_umb = logisticR.predict_proba(X_test.values)\n",
    "y_probs_umb_data = y_probs_umb[:,1]\n",
    "y_pred_umb = y_probs_umb_data > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy =', accuracy_score(y_test, y_pred_umb).round(2))\n",
    "print('Recall =', recall_score(y_test, y_pred_umb).round(2))\n",
    "print('Precision =', precision_score(y_test, y_pred_umb).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_umb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_votos = confusion_matrix(y_test, y_pred_umb)\n",
    "plt.plot(30)\n",
    "ax = sns.heatmap(cm_votos, annot=True, cmap=\"RdYlGn\", cbar=False,\n",
    "                    annot_kws={\"size\": 14}, fmt='g')\n",
    "\n",
    "plt.title('Matriz de confusión', size =16)\n",
    "plt.xlabel('Valores previstos', size = 13)\n",
    "plt.ylabel('Valores verdaderos', size=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Optimización vía Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca el mejor hiperparámetro. Debido a que la base de datos es muy chica, se puede utilizar Grid Search en vez de Random Search pues el tiempo de ejecución no es un obstáculo y el primero arroja mejores resultados. Se probó también con alteraciones de solver pero resultaba en ineficacia de convergencia u otros warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_logistic_accuracy = GridSearchCV(LogisticRegression(),  {'C': [1, 10, 100, 1000]}, cv=5, scoring='accuracy')\n",
    "grid_search_logistic_accuracy.fit(X_train_std, y_train)\n",
    "\n",
    "print(grid_search_logistic_accuracy.best_score_.round(2))\n",
    "print(grid_search_logistic_accuracy.best_params_)\n",
    "print(grid_search_logistic_accuracy.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_logistic_recall = GridSearchCV(LogisticRegression(),  {'C': [1, 10, 100, 1000]}, cv=5, scoring='recall')\n",
    "grid_search_logistic_recall.fit(X_train_std, y_train)\n",
    "\n",
    "print(grid_search_logistic_recall.best_score_.round(2))\n",
    "print(grid_search_logistic_recall.best_params_)\n",
    "print(grid_search_logistic_recall.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_logistic_precision = GridSearchCV(LogisticRegression(),  {'C': [1, 10, 100, 1000]}, cv=5, scoring='precision')\n",
    "grid_search_logistic_precision.fit(X_train_std, y_train)\n",
    "\n",
    "print(grid_search_logistic_precision.best_score_.round(2))\n",
    "print(grid_search_logistic_precision.best_params_)\n",
    "print(grid_search_logistic_precision.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gs = grid_search_logistic_accuracy.predict(X_test.values) #Se utiliza el de accuracy, pero con los 3 el resultado de la matriz es el mismo\n",
    "cm_votos = confusion_matrix(y_test, y_pred_gs)\n",
    "plt.plot(30)\n",
    "ax = sns.heatmap(cm_votos, annot=True, cmap=\"RdYlGn\", cbar=False,\n",
    "                    annot_kws={\"size\": 14}, fmt='g')\n",
    "\n",
    "plt.title('Matriz de confusión', size =16)\n",
    "plt.xlabel('Valores previstos', size = 13)\n",
    "plt.ylabel('Valores verdaderos', size=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Análisis de la curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_nb,tpr_nb,thr_nb = roc_curve(y_test, y_probs_nb[:,1])\n",
    "fpr_log,tpr_log,thr_log = roc_curve(y_test, y_probs_umb[:,1])\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.axis([0, 1.01, 0, 1.01])\n",
    "plt.xlabel('1 - Specificty')\n",
    "plt.ylabel('TPR / Sensitivity')\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_nb,tpr_nb)\n",
    "plt.plot(fpr_log,tpr_log)\n",
    "plt.plot(np.arange(0,1, step =0.01), np.arange(0,1, step =0.01))\n",
    "plt.legend(['Naive Bayes','Regresión Logística'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a calcular el AUC para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC con Naive Bayes:', auc(fpr_nb, tpr_nb))\n",
    "print('AUC con Regresión Logística:', auc(fpr_log, tpr_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Comparación de las métricas de los diferente modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se graficará el rendimiento de los 5 modelos usados (Valor mayoritario, Naive Bayes, Regresión logística, Regresión logística con umbral y Regresión logística con Grid Search) según las 3 métricas: accuracy, precision y recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_valor_mayoritario = y_test.value_counts(normalize=True).max()\n",
    "Accuracy_NB =  accuracy_score(y_test, y_preds_nb)\n",
    "Accuracy_RL = accuracy_score(y_test, y_pred_lg)\n",
    "Accuracy_RL_umbral = accuracy_score(y_test, y_pred_umb)\n",
    "Accuracy_GS = grid_search_logistic_accuracy.best_score_\n",
    "\n",
    "Accuracy_plot = Accuracy_valor_mayoritario, Accuracy_NB, Accuracy_RL, Accuracy_RL_umbral, Accuracy_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_valor_mayoritario = (votos_final['Target'] == 1).sum()/(votos_final['Target'] == 1).sum() + 0 # Se suma 0 pues no hay falsos negativos al calcular según la clase mayoritaria\n",
    "Recall_NB = recall_score(y_test, y_preds_nb).round(2)\n",
    "Recall_RL = recall_score(y_test, y_pred_lg).round(2)\n",
    "Recall_RL_umbral = recall_score(y_test, y_pred_umb).round(2)\n",
    "Recall_GS = grid_search_logistic_recall.best_score_.round(2)\n",
    "\n",
    "Recall_plot = Recall_valor_mayoritario, Recall_NB, Recall_RL, Recall_RL_umbral, Recall_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_valor_mayoritario = (votos_final['Target'] == 1).sum()/votos_final.Target.count()\n",
    "Precision_NB = precision_score(y_test, y_preds_nb).round(2)\n",
    "Precision_RL = precision_score(y_test, y_pred_lg).round(2)\n",
    "Precision_RL_umbral= precision_score(y_test, y_pred_umb).round(2)\n",
    "Precision_GS = grid_search_logistic_precision.best_score_.round(2)\n",
    "\n",
    "Precision_plot = Precision_valor_mayoritario, Precision_NB, Precision_RL, Precision_RL_umbral, Precision_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_valor_mayoritario = 2*((Precision_valor_mayoritario * Recall_valor_mayoritario) / (Precision_valor_mayoritario + Recall_valor_mayoritario)).round(2)\n",
    "F1_NB = f1_score(y_test,y_preds_nb).round(2)\n",
    "F1_RL = f1_score(y_test, y_pred_lg).round(2)\n",
    "F1_RL_umbral= f1_score(y_test, y_pred_umb).round(2)\n",
    "F1_GS = 2*((Precision_GS*Recall_GS) / (Precision_GS+Recall_GS)).round(2)\n",
    "\n",
    "F1_plot = F1_valor_mayoritario, F1_NB, F1_RL, F1_RL_umbral, F1_GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10)).suptitle('Comparación de rendimiento según las 3 métricas', y=0.3, fontsize = 24, color='white', backgroundcolor='gray')\n",
    "plt.plot(Accuracy_plot, color='red', linewidth=2, label = \"Accuracy\")\n",
    "plt.plot(Recall_plot, color='blue', linewidth=2, linestyle = \"--\", label = \"Recall\")\n",
    "plt.plot(Precision_plot, color='green', linewidth=2, label = \"Precision\")\n",
    "plt.plot(F1_plot, color='y', linewidth=2, linestyle = \"--\", label = \"F1 score\")\n",
    "plt.xlabel('Métodos', fontsize=22)\n",
    "plt.ylabel('Rendimiento', fontsize=22)\n",
    "plt.legend(fontsize = 17)\n",
    "\n",
    "\n",
    "axes= plt.gca()\n",
    "ymin= .60\n",
    "ymax= 1.01\n",
    "axes.set_ylim([ymin, ymax])\n",
    "\n",
    "plt.axvline(x='Valor mayoritario', color=\"grey\", linestyle=\"--\", lw=1.3)\n",
    "plt.axvline(x='Naive Bayes',color=\"grey\", linestyle=\"--\", lw=1.3)\n",
    "plt.axvline(x='Regr. Logística', color=\"grey\", linestyle=\"--\", lw=1.3)\n",
    "plt.axvline(x='Regr, Logística con Umbral' , color=\"grey\", linestyle=\"--\", lw=1.3)\n",
    "plt.axvline(x='Regr. Logística con Grid Search', color=\"grey\", linestyle=\"--\", lw=1.3)\n",
    "plt.grid(which='major', axis='y', color='black', lw=0.4, alpha=0.6)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
